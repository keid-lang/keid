namespace keidc::parser

import (
    core::collections
    core::error
    core::string
    core::object
    keidc::ast
    keidc::common
    keidc::ksdl
    keidc::types
    std::fs
    std::io
)

function tokenize<T>(loc: TokenLocation, node: T): AstToken<T> {
    return new AstToken<T> {
        node
        loc
    }
}

function tokenizeIdentifier(token: LexerToken): AstToken<string> {
    return new AstToken<string> {
        node = token.kind.identifier()
        loc = token.originalLoc
    }
}

function parseQualifiedPath(ast: RuleMatch): AstToken<string> {
    if ast.ruleName != "QualifiedPath" {
        throw Error.create(string.format("parseQualifiedPath for invalid rule '", ast.ruleName, "'"))
    }
    let fullPath = StringBuilder.withCapacity(ast.loc.length)
    let pathGroup = ast.getGroup("path")
    for i in range.create(pathGroup.length - 1) {
        let ident = pathGroup.elementAt(i).token().kind.identifier()
        fullPath.append(ident)
        fullPath.append(".")
    }
    let lastIdent = pathGroup.elementAt(pathGroup.length - 1).token().kind.identifier()
    fullPath.append(lastIdent)
    return tokenize<string>(ast.loc, fullPath.toString())
}

public enum PrattParserAffix {
    Prefix
    Infix
    Postfix
}

implement ToString for PrattParserAffix {
    toString(): string => match this {
        Prefix => "Prefix"
        Infix => "Infix"
        Postfix => "Postfix"
    }
}

const PRECEDENCE_STEP: uint32 = 10
const OPERATORS: [PrattParserOperator] = new PrattParserOperator[
    PrattParserOperator.create(PrattParserAffix.Infix,   ".",     AstOperator.MemberAccess,        PRECEDENCE_STEP * 1),
    PrattParserOperator.create(PrattParserAffix.Infix,   "??",    AstOperator.NullCoalesce,        PRECEDENCE_STEP * 2),
    PrattParserOperator.create(PrattParserAffix.Infix,   "or",    AstOperator.BooleanOr,           PRECEDENCE_STEP * 3),
    PrattParserOperator.create(PrattParserAffix.Infix,   "and",   AstOperator.BooleanAnd,          PRECEDENCE_STEP * 4),
    PrattParserOperator.create(PrattParserAffix.Infix,   "==",    AstOperator.Equals,              PRECEDENCE_STEP * 5),
    PrattParserOperator.create(PrattParserAffix.Infix,   "!=",    AstOperator.NotEquals,           PRECEDENCE_STEP * 5),
    PrattParserOperator.create(PrattParserAffix.Infix,   "<",     AstOperator.LessThan,            PRECEDENCE_STEP * 6),
    PrattParserOperator.create(PrattParserAffix.Infix,   "<=",    AstOperator.LessThanOrEquals,    PRECEDENCE_STEP * 6),
    PrattParserOperator.create(PrattParserAffix.Infix,   ">",     AstOperator.GreaterThan,         PRECEDENCE_STEP * 6),
    PrattParserOperator.create(PrattParserAffix.Infix,   ">=",    AstOperator.GreaterThanOrEquals, PRECEDENCE_STEP * 6),
    PrattParserOperator.create(PrattParserAffix.Infix,   "<<",    AstOperator.LeftShift,           PRECEDENCE_STEP * 7),
    PrattParserOperator.create(PrattParserAffix.Infix,   ">>",    AstOperator.RightShift,          PRECEDENCE_STEP * 7),
    PrattParserOperator.create(PrattParserAffix.Infix,   "+",     AstOperator.Add,                 PRECEDENCE_STEP * 8),
    PrattParserOperator.create(PrattParserAffix.Infix,   "-",     AstOperator.Subtract,            PRECEDENCE_STEP * 8),
    PrattParserOperator.create(PrattParserAffix.Infix,   "*",     AstOperator.Multiply,            PRECEDENCE_STEP * 9),
    PrattParserOperator.create(PrattParserAffix.Infix,   "/",     AstOperator.Divide,              PRECEDENCE_STEP * 9),
    PrattParserOperator.create(PrattParserAffix.Infix,   "%",     AstOperator.Modulus,             PRECEDENCE_STEP * 9),
    PrattParserOperator.create(PrattParserAffix.Infix,   "as",    AstOperator.As,                  PRECEDENCE_STEP * 10),
    PrattParserOperator.create(PrattParserAffix.Prefix,  "not",   AstOperator.Not,                 PRECEDENCE_STEP * 11),
    PrattParserOperator.create(PrattParserAffix.Prefix,  "ref",   AstOperator.Ref,                 PRECEDENCE_STEP * 12),
    PrattParserOperator.create(PrattParserAffix.Prefix,  "deref", AstOperator.Deref,               PRECEDENCE_STEP * 12),
    PrattParserOperator.create(PrattParserAffix.Prefix,  "...",   AstOperator.Spread,              PRECEDENCE_STEP * 13),
    PrattParserOperator.create(PrattParserAffix.Postfix, "!",     AstOperator.NonNullAssertion,    PRECEDENCE_STEP * 14),
]

public class PrattParserOperator {
    affix: PrattParserAffix
    text: string
    ast: AstOperator
    precedence: uint32

    public static create(affix: PrattParserAffix, text: string, ast: AstOperator, precedence: uint32): PrattParserOperator => new PrattParserOperator { affix, text, ast, precedence, }
}

implement ToString for PrattParserOperator {
    toString(): string => string.format("PrattParserOperator(affix=", this.affix.toString(), ", text=", this.text, ", ast=", this.ast.toString(), ", precedence=" + this.precedence.toString(), ")")
}

public class PrattParser {
    parts: List<ParserMatch>
    offset: usize
    operators: [PrattParserOperator]
    primaryParser: function (ast: ParserMatch) => AstToken<AstExpr>
    prefixParser: function (op: AstToken<AstOperator>, operand: AstToken<AstExpr>) => AstToken<AstExpr>
    infixParser: function (lhs: AstToken<AstExpr>, op: AstToken<AstOperator>, rhs: AstToken<AstExpr>) => AstToken<AstExpr>
    postfixParser: function (operand: AstToken<AstExpr>, op: AstToken<AstOperator>) => AstToken<AstExpr>

    public parse(): AstToken<AstExpr> {
        return this.expr(0)
    }

    findOperator(text: string): ?PrattParserOperator {
        for operator in this.operators {
            if operator.text == text {
                return operator
            }
        }

        return null
    }

    expr(rbp: uint32): AstToken<AstExpr> {
        let lhs = this.nud()
        while rbp < this.lbp() {
            lhs = this.led(lhs)
        }
        return lhs
    }

    lbp(): uint32 {
        if this.offset == this.parts.length {
            return 0
        }
        let next = this.parts.elementAt(this.offset)
        match next {
            Token { token, } => {
                match token.kind {
                    Operator { op, } => {
                        let prattOp = this.findOperator(op)
                        if prattOp == null {
                            throw Error.create("No such operator: " + op)
                        }
                        return prattOp!.precedence
                    }
                    _ => {}
                }
            }
            _ => {}
        }
        return 0
    }

    led(lhs: AstToken<AstExpr>): AstToken<AstExpr> {
        let next = this.parts.elementAt(this.offset)
        this.offset += 1
        match next {
            Rule { rule, } => {
                match rule.ruleName {
                    "InfixOperator" => {
                        let op = ""
                        match rule.getGroupValue("op") {
                            Token { token, } => {
                                op = token.kind.operator()
                            }
                            Rule { rule, } => {
                                op = match rule.ruleName {
                                    "LeftShift" => "<<"
                                    "RightShift" => ">>"
                                    _ => throw Error.create("invalid infix operator rule: " + rule.ruleName)
                                }
                            }
                        }
                        let infixOperator = this.findOperator(op)
                        if infixOperator == null {
                            throw Error.create("No such operator: " + op)
                        }
                        let rhs = this.expr(infixOperator!.precedence)
                        return (this.infixParser)(lhs, tokenize<AstOperator>(rule.loc, infixOperator!.ast), rhs)
                    }
                    "PostfixOperator" => {
                        let op2 = rule.getGroupValue("op").token().kind.operator()
                        let postfixOperator = this.findOperator(op2)
                        if postfixOperator == null {
                            throw Error.create("No such operator: " + op2)
                        }
                        return (this.postfixParser)(lhs, tokenize<AstOperator>(rule.loc, postfixOperator!.ast))
                    }
                    _ => {}
                }
            }
        }
        throw Error.create("expected infix or postfix expression")
    }

    nud(): AstToken<AstExpr> {
        let next = this.parts.elementAt(this.offset)
        this.offset += 1
        match next {
            Rule { rule, } => {
                if rule.ruleName == "PrefixOperator" {
                    let op = rule.getGroupValue("op").token().kind.operator()
                    let prefixOperator = this.findOperator(op)
                    if prefixOperator == null {
                        throw Error.create("No such operator: " + op)
                    }
                    let rhs = this.expr(prefixOperator!.precedence - 1)
                    return (this.prefixParser)(tokenize<AstOperator>(rule.loc, prefixOperator!.ast), rhs)
                }
            }
            _ => {}
        }
        return (this.primaryParser)(next)
    }
}

class KeidParser {
    scope: DeclarationScope
    file: SourceFile

    parseGenericDecls(ast: RuleMatch): List<AstGenericDecl> {
        let decls = List.empty<AstGenericDecl>()
        for decl in ast.getGroup("decls") {
            decls.push(new AstGenericDecl {
                name = tokenizeIdentifier(decl.rule().getGroupValue("name").token())
            })
        }
        return decls
    }

    parseGenericArgs(ast: RuleMatch, group: string): ?List<AstToken<ComplexType>> {
        if ast.hasGroup(group) {
            let args = List.empty<AstToken<ComplexType>>()
            for arg in ast.getGroupValue(group).rule().getGroup("args") {
                args.push(this.parseValueType(arg.rule()))
            }
            return args
        }
        return null
    }

    parseGenericArgsNodes(ast: RuleMatch): List<ComplexType> {
        let args = List.empty<ComplexType>()
        if ast.hasGroup("generics") {
            for arg in ast.getGroupValue("generics").rule().getGroup("args") {
                args.push(this.parseValueTypeNode(arg.rule()))
            }
        }
        return args
    }

    parseModifers(parentAstNode: RuleMatch): List<AstToken<Modifier>> {
        if parentAstNode.hasGroup("modifiers") {
            let astModifiers = parentAstNode.getGroup("modifiers")
            let modifiers = List.withCapacity<AstToken<Modifier>>(astModifiers.length)
            for astModifier in astModifiers {
                let modifierToken = astModifier.token()
                let modifierName = modifierToken.kind.keyword()
                let modifier = match modifierName {
                    "public" => Modifier.Public
                    "extern" => Modifier.Extern
                    "static" => Modifier.Static
                    "namespace" => Modifier.Namespace
                    "constructor" => Modifier.Constructor
                    "unsafe" => Modifier.Unsafe
                    "abstract" => Modifier.Abstract
                    "override" => Modifier.Override
                    _ => throw Error.create("invalid modifier: " + modifierName)
                }
                modifiers.push(new AstToken<Modifier> {
                    node = modifier
                    loc = modifierToken.loc
                })
            }
            return modifiers
        }
        return List.empty<AstToken<Modifier>>()
    }

    parseNewSliceExpr(ast: RuleMatch): AstToken<AstExpr> {
        let type = this.parseValueType(ast.getGroupValue("type").rule())
        let initialValue = this.parseExpr(ast.getGroupValue("initialValue").rule())
        let length = this.parseExpr(ast.getGroupValue("length").rule())
        return tokenize<AstExpr>(ast.loc, new AstExpr.NewSlice {
            type
            initialValue
            length
        })
    }

    parseFuncCallExpr(ast: RuleMatch): AstToken<AstExpr> {
        let callee = match ast.getGroupValue("callee") {
            Rule { rule, } => this.parseExpr(rule)
            Token { token, } => match token.kind {
                Identifier { name, } => tokenize<AstExpr>(token.loc, new AstExpr.Ident {
                    value = name
                })
                // "this" and "super" are valid callee identifiers tokenized as a keyword
                Keyword { name, } => tokenize<AstExpr>(token.loc, new AstExpr.Ident {
                    value = name
                })
                _ => throw Error.create("invalid func call expr callee token: " + token.kind.toString())
            }
        }
        let generics = this.parseGenericArgs(ast, "generics")
        let astParams = match ast.hasGroup("params") {
            true => ast.getGroup("params")
            false => List.empty<ParserMatch>()
        }
        let params = List.withCapacity<AstToken<AstExpr>>(astParams.length)
        for astParam in astParams {
            params.push(this.parseExpr(astParam.rule()))
        }
        return tokenize<AstExpr>(ast.loc, new AstExpr.FuncCall {
            callee
            generics
            params
        }) 
    }

    parseConstSliceExpr(ast: RuleMatch): AstToken<AstExpr> {
        let type = this.parseValueType(ast.getGroupValue("type").rule())
        let astElements = match ast.hasGroup("elements") {
            true => ast.getGroup("elements")
            false => List.empty<ParserMatch>()
        }
        let elements = List.withCapacity<AstToken<AstExpr>>(astElements.length)
        for astElement in astElements {
            elements.push(this.parseExpr(astElement.rule()))
        }

        return tokenize<AstExpr>(ast.loc, new AstExpr.ConstSlice {
            type
            elements
        })
    }

    parseNewExpr(ast: RuleMatch): AstToken<AstExpr> {
        let type = this.parseValueType(ast.getGroupValue("type").rule())
        let astFields = ast.getGroupValue("fields").rule().getGroup("fields")
        let fields = List.withCapacity<AstField>(astFields.length)

        for astField in astFields {
            let rule = astField.rule()
            let name = tokenizeIdentifier(rule.getGroupValue("name").token())
            let value: ?AstToken<AstExpr> = null
            if rule.hasGroup("value") {
                value = this.parseExpr(rule.getGroupValue("value").rule())
            }

            fields.push(new AstField { name, value, })
        }
        
        return tokenize<AstExpr>(ast.loc, new AstExpr.NewObject {
            type
            fields
        })
    }

    parseDeconstructionExpr(ast: RuleMatch): List<AstDestructionMember> {
        let astMembers = ast.getGroup("members")
        let members = List.withCapacity<AstDestructionMember>(astMembers.length)
        for astMember in astMembers {
            match astMember {
                Rule { rule, } => {
                    let name = tokenizeIdentifier(rule.getGroupValue("name").token())
                    let alias: ?AstToken<string> = null
                    if rule.hasGroup("alias") {
                        alias = tokenizeIdentifier(rule.getGroupValue("alias").token())
                    }
                    let type: ?AstToken<ComplexType> = null
                    if rule.hasGroup("type") {
                        type = this.parseValueType(rule.getGroupValue("type").rule())
                    }

                    members.push(new AstDestructionMember.Field {
                        field = new AstDestructionMemberField {
                            name
                            alias
                            type
                        }
                    })
                }
                Token { token, } => {
                    members.push(AstDestructionMember.Ellipsis)
                }
            }
        }
        return members
    }

    parseMatchTestEnumWithData(ast: RuleMatch): MatchArmKind {
        let variant = tokenizeIdentifier(ast.getGroupValue("variant").token())
        let data = this.parseDeconstructionExpr(ast.getGroupValue("data").rule())
        return new MatchArmKind.EnumWithData {
            variant
            data
        }
    }

    parseMatchExpr(ast: RuleMatch): AstToken<AstExpr> {
        let operand = this.parseExpr(ast.getGroupValue("operand").rule())
        let astArms = ast.getGroup("arms")
        let arms = List.withCapacity<AstMatchArm>(astArms.length)
        for astArm in astArms {
            let astTest = astArm.rule().getGroupValue("test")
            let kind = match astTest {
                Rule { rule, } => this.parseMatchTestEnumWithData(rule)
                Token { token, } => match token.kind {
                    Literal { lit, } => new MatchArmKind.Literal {
                        lit = tokenize<LexerLiteral>(token.loc, lit)
                    }
                    Identifier { name, } => new MatchArmKind.Identifier {
                        ident = tokenize<string>(token.loc, name)
                    }
                    Operator { op, } => MatchArmKind.CatchAll
                    _ => throw Error.create("invalid match arm test token: " + token.toString())
                }
            }
            let statement = this.parseBlockStatement(astArm.rule().getGroupValue("statement").rule())
            arms.push(new AstMatchArm {
                kind
                statement
            })
        }

        return tokenize<AstExpr>(ast.loc, new AstExpr.Match {
            operand
            arms
        })
    }

    parseThrow(ast: RuleMatch): AstToken<AstExpr> {
        let error = this.parseExpr(ast.getGroupValue("error").rule())
        return tokenize<AstExpr>(ast.loc, new AstExpr.Throw {
            error
        })
    }

    parseIfStatement(ast: RuleMatch): AstStatement {
        let tests = ast.getGroup("tests")
        let conditionalBlocks = ast.getGroup("conditionalBlocks")

        if tests.length != conditionalBlocks.length {
            unreachable
        }

        let conditionals = List.empty<AstIfBlock>()
        for i in range.create(tests.length) {
            let condition = this.parseExpr(tests.elementAt(i).rule())
            let block = this.parseCodeBlock(conditionalBlocks.elementAt(i).rule())
            conditionals.push(new AstIfBlock {
                condition
                block
            })
        }

        let fallback: ?List<AstToken<AstStatement>> = null
        if ast.hasGroup("fallback") {
            fallback = this.parseCodeBlock(ast.getGroupValue("fallback").rule())
        }

        return new AstStatement.IfChain {
            conditionals
            fallback
        }
    }

    parseForLoop(ast: RuleMatch): AstStatement {
        let condition = this.parseExpr(ast.getGroupValue("condition").rule())
        let block = this.parseCodeBlock(ast.getGroupValue("block").rule())

        return new AstStatement.ForLoop {
            condition
            block
        }
    }

    parseForEachLoop(ast: RuleMatch): AstStatement {
        let elementName = tokenizeIdentifier(ast.getGroupValue("elementName").token())
        let iterable = this.parseExpr(ast.getGroupValue("iterable").rule())
        let block = this.parseCodeBlock(ast.getGroupValue("block").rule())

        return new AstStatement.ForEachLoop {
            elementName
            iterable
            block
        }
    }

    parseWithStatement(ast: RuleMatch): AstStatement {
        let binding = this.parseLet(ast.getGroupValue("binding").rule())
        let block = this.parseCodeBlock(ast.getGroupValue("block").rule())

        return new AstStatement.With {
            binding
            block
        }
    }

    parseReturn(ast: RuleMatch): AstStatement {
        let operand: ?AstToken<AstExpr> = null
        if ast.hasGroup("operand") {
            operand = this.parseExpr(ast.getGroupValue("operand").rule())
        }
        return new AstStatement.Return {
            operand
        }
    }

    parsePrefixExpr(operator: AstToken<AstOperator>, operand: AstToken<AstExpr>): AstToken<AstExpr> {
        return new AstToken<AstExpr> {
            node = new AstExpr.Unary {
                operator
                operand
            }
            loc = operator.loc.joined(operand.loc)
        }
    }

    parseInfixExpr(lhs: AstToken<AstExpr>, operator: AstToken<AstOperator>, rhs: AstToken<AstExpr>): AstToken<AstExpr> {
        return new AstToken<AstExpr> {
            node = new AstExpr.Binary {
                lhs
                operator
                rhs
            }
            loc = lhs.loc.joined(rhs.loc)
        }
    }

    parsePostfixExpr(operand: AstToken<AstExpr>, operator: AstToken<AstOperator>): AstToken<AstExpr> {
        return new AstToken<AstExpr> {
            node = new AstExpr.Unary {
                operator
                operand
            }
            loc = operand.loc.joined(operator.loc)
        }
    }

    parseExprOperand(operand: ParserMatch): AstToken<AstExpr> {
        match operand {
            Rule { rule, } => {
                match rule.ruleName {
                    "Expr" => return this.parseExpr(rule)
                    "GroupingExpr" => return this.parseExprOperand(rule.getGroupValue("expr"))
                    "NewSliceExpr" => return this.parseNewSliceExpr(rule)
                    "FuncCallExpr" => return this.parseFuncCallExpr(rule)
                    "NewExpr" => return this.parseNewExpr(rule)
                    "ConstSliceExpr" => return this.parseConstSliceExpr(rule)
                    "MatchExpr" => return this.parseMatchExpr(rule)
                    _ => throw Error.create(string.format("invalid rule as expr operand '", rule.ruleName, "'"))
                }
            }
            Token { token, } => {
                match token.kind {
                    Identifier { name, } => {
                        return tokenize<AstExpr>(token.loc, new AstExpr.Ident {
                            value = name
                        })
                    }
                    // treat keywords in an expr as identifiers; they will be either "this" or "super"
                    Keyword { name, } => {
                        return tokenize<AstExpr>(token.loc, new AstExpr.Ident {
                            value = name
                        })
                    }
                    Literal { lit, } => {
                        return tokenize<AstExpr>(token.loc, new AstExpr.Literal {
                            lit
                        })
                    }
                    _ => throw Error.create("invalid expr operand token kind: " + token.kind.toString())
                }
            }
        }
        unreachable
    }

    parseExpr(expr: RuleMatch): AstToken<AstExpr> {
        let pratt = new PrattParser {
            parts = expr.getGroup("parts")
            offset = 0
            operators = OPERATORS
            primaryParser = this.parseExprOperand
            prefixParser = this.parsePrefixExpr
            infixParser = this.parseInfixExpr
            postfixParser = this.parsePostfixExpr
        }
        return pratt.parse()
    }

    parseBody(bodyDecl: RuleMatch): List<AstToken<AstStatement>> {
        match bodyDecl.ruleName {
            "CodeBlock" => return this.parseCodeBlock(bodyDecl)
            "ArrowBlock" => {
                this.scope = DeclarationScope.Function

                let exprDecl = bodyDecl.getGroupValue("expr").rule()
                let expr = this.parseExpr(exprDecl)
                let statement = new AstStatement.Expr {
                    value = expr
                }
                return List.from<AstToken<AstStatement>>(tokenize<AstStatement>(exprDecl.loc, statement))
            }
            _ => throw Error.create("invalid body rule kind: " + bodyDecl.ruleName)
        }
    }

    parseBlockStatement(ast: RuleMatch): AstToken<AstStatement> {
        return tokenize<AstStatement>(ast.loc, match ast.ruleName {
            "ReturnStatement" => this.parseReturn(ast)
            "ExprStatement" => new AstStatement.Expr { value = this.parseExpr(ast.getGroupValue("expr").rule()), }
            "UnsafeBlock" => new AstStatement.UnsafeBlock { statements = this.parseCodeBlock(ast.getGroupValue("inner").rule()) }
            "LetStatement" => new AstStatement.Let { statement = this.parseLet(ast.getGroupValue("let").rule()) }
            "AssignStatement" => new AstStatement.Assign { statement = this.parseAssign(ast) }
            "ThrowStatement" => new AstStatement.Throw { error = this.parseExpr(ast.getGroupValue("error").rule()) }
            "IfStatement" => this.parseIfStatement(ast)
            "ForLoop" => this.parseForLoop(ast)
            "ForEachLoop" => this.parseForEachLoop(ast)
            "IndefiniteLoop" => new AstStatement.IndefiniteLoop { block = this.parseCodeBlock(ast.getGroupValue("block").rule()) }
            "WithStatement" => this.parseWithStatement(ast)
            _ => throw Error.create("NotYetImplemented: block statement: " + ast.ruleName)
        })
    }

    parseCodeBlock(ast: RuleMatch): List<AstToken<AstStatement>> {
        let statements = List.empty<AstToken<AstStatement>>()
        if ast.hasGroup("statements") {
            for statement in ast.getGroup("statements") {
                this.scope = DeclarationScope.Function
                statements.push(this.parseBlockStatement(statement.rule()))
            }
        }
        return statements
    }

    parseValueTypeNode(ast: RuleMatch): ComplexType {
        match ast.ruleName {
            "CompoundType" => {
                let astTypes = ast.getGroup("types")
                let types = List.withCapacity<ComplexType>(astTypes.length)
                for astType in astTypes {
                    types.push(this.parseValueTypeNode(astType.rule()))
                }
                return new ComplexType.Compound {
                    types
                }
            }
            "SliceType" => {
                return new ComplexType.Slice {
                    element = this.parseValueTypeNode(ast.getGroupValue("elementType").rule())
                }
            }
            "ArrayType" => {
                throw Error.create("TODO: ArrayType")
            }
            "NullableType" => return new ComplexType.Nullable {
                element = this.parseValueTypeNode(ast.getGroupValue("elementType").rule())
            }
            "BasicType" => {
                let path = match ast.getGroupValue("path") {
                    Rule { rule, } => parseQualifiedPath(rule)
                    Token { token, } => match token.kind {
                        // "This" keyword is a valid BasicType
                        Keyword { name, } => tokenize<string>(token.loc, name)
                        _ => throw Error.create("invalid token type for BasicType: " + token.kind.toString())
                    }
                }
                let generics = this.parseGenericArgsNodes(ast)
                let basic = match path.node {
                    "void"    => BasicType.Void
                    "never"   => BasicType.Never
                    "bool"    => BasicType.Bool
                    "char"    => BasicType.Char
                    "uint8"   => BasicType.UInt8
                    "uint16"  => BasicType.UInt16
                    "uint32"  => BasicType.UInt32
                    "uint64"  => BasicType.UInt64
                    "int8"    => BasicType.Int8
                    "int16"   => BasicType.Int16
                    "int32"   => BasicType.Int32
                    "int64"   => BasicType.Int64
                    "float32" => BasicType.Float32
                    "float64" => BasicType.Float64
                    "usize"   => BasicType.USize
                    "isize"   => BasicType.ISize
                    _ => return new ComplexType.Basic {
                        basic = new BasicType.Ident {
                            ident = new QualifiedIdent {
                                name = path.node
                                generics
                            }
                        }
                    }
                }
                if generics.length > 0 {
                    throw Error.create("parser error: primitive cannot have generics")
                }
                return new ComplexType.Basic {
                    basic
                }
            }
            _ => throw Error.create(string.format("invalid rule for parseValueType: ", ast.ruleName))
        }
    }

    parseValueType(ast: RuleMatch): AstToken<ComplexType> => tokenize<ComplexType>(ast.loc, this.parseValueTypeNode(ast))

    parseLet(ast: RuleMatch): AstLet {
        let kindName = ast.getGroupValue("kind").token().kind.keyword()
        let kind = match kindName {
            "let" => LetKind.Mutable
            "const" => LetKind.Constant
            _ => throw Error.create(string.format("invalid let kind: ", kindName))
        }
        let name = tokenizeIdentifier(ast.getGroupValue("name").token())
        let valueType: ?AstToken<ComplexType> = null
        if ast.hasGroup("valueType") {
            valueType = this.parseValueType(ast.getGroupValue("valueType").rule())
        }
        let initialValue: ?AstToken<AstExpr> = null
        if ast.hasGroup("initialValue") {
            initialValue = this.parseExpr(ast.getGroupValue("initialValue").rule())
        }

        let astSecondaries = match ast.hasGroup("secondaries") {
            true => ast.getGroup("secondaries")
            false => List.empty<ParserMatch>()
        }
        let decls = List.withCapacity<AstLetVariableDecl>(astSecondaries.length + 1)
        decls.push(new AstLetVariableDecl {
            name
            initialValue
        })
        for astSecondary in astSecondaries {
            let rule = astSecondary.rule()
            let secondaryName = tokenizeIdentifier(rule.getGroupValue("name").token())
            let secondaryInitialValue: ?AstToken<AstExpr> = null
            if rule.hasGroup("initialValue") {
                secondaryInitialValue = this.parseExpr(rule.getGroupValue("initialValue").rule())
            }
            decls.push(new AstLetVariableDecl {
                name = secondaryName
                initialValue = secondaryInitialValue
            })
        }

        return new AstLet {
            scope = this.scope
            kind
            valueType
            decls
        }
    }

    parseOperator(ast: LexerToken): AstToken<AstOperator> {
        match ast.kind {
            Operator { op, } => {
                for operator in OPERATORS {
                    if operator.text == op {
                        return tokenize<AstOperator>(ast.loc, operator.ast)
                    }
                }
            }
            _ => {}
        }
        throw Error.create(string.format("invalid operator: ", ast.toString()))
    }

    parseSelfOperator(ast: LexerToken): AstToken<AstOperator> {
        match ast.kind {
            Operator { op, } => {
                if op == "=" {
                    return tokenize<AstOperator>(ast.loc, AstOperator.Assign)
                }
                let unself = op.substringBefore(op.length - 1)
                for operator in OPERATORS {
                    if operator.text == unself {
                        return tokenize<AstOperator>(ast.loc, operator.ast)
                    }
                }
            }
            _ => {}
        }
        throw Error.create(string.format("invalid self operator: ", ast.toString()))
    }

    parseAssign(ast: RuleMatch): AstAssign {
        let deref = ast.hasGroup("deref")
        let lhs = this.parseExpr(ast.getGroupValue("lhs").rule())
        let op = this.parseSelfOperator(ast.getGroupValue("op").token())
        let rhs = this.parseExpr(ast.getGroupValue("rhs").rule())

        return new AstAssign {
            deref
            lhs
            op
            rhs
        }
    }

    parseClassField(ast: RuleMatch): AstClassField {
        let modifiers = this.parseModifers(ast)
        let name = tokenizeIdentifier(ast.getGroupValue("name").token())
        let type = this.parseValueType(ast.getGroupValue("type").rule())
        let initialValue: ?AstToken<AstExpr> = null
        if ast.hasGroup("initialValue") {
            initialValue = this.parseExpr(ast.getGroupValue("initialValue").rule())
        }
        return new AstClassField {
            modifiers
            name
            type
            initialValue
        }
    }

    parseFunctionParam(paramDecl: RuleMatch): AstFunctionParam {
        return new AstFunctionParam {
            name = tokenizeIdentifier(paramDecl.getGroupValue("name").token())
            type = this.parseValueType(paramDecl.getGroupValue("type").rule())
        }
    }

    parseFunction(decl: RuleMatch): AstFunction {
        let modifiers = this.parseModifers(decl)
        let name = tokenizeIdentifier(decl.getGroupValue("name").token())
        let generics: ?List<AstGenericDecl> = null
        if decl.hasGroup("generics") {
            generics = this.parseGenericDecls(decl.getGroupValue("generics").rule())
        }
        let params = List.empty<AstFunctionParam>()
        let paramsDecl = decl.getGroupValue("params").rule()
        if paramsDecl.hasGroup("params") {
            for paramDecl in paramsDecl.getGroup("params") {
                params.push(this.parseFunctionParam(paramDecl.rule()))
            }
        }

        let returnType: ?AstToken<ComplexType> = null
        if decl.hasGroup("returnType") {
            returnType = this.parseValueType(decl.getGroupValue("returnType").rule())
        }

        let varargs = VarargsMode.None
        if paramsDecl.hasGroup("nativeVarargs") {
            varargs = VarargsMode.Native
        } else if paramsDecl.hasGroup("varargs") {
            let paramDecl = paramsDecl.getGroupValue("varargs").rule().getGroupValue("param").rule()
            varargs = new VarargsMode.Array {
                param = this.parseFunctionParam(paramDecl)
            }
        }

        let body: ?List<AstToken<AstStatement>> = null
        if decl.hasGroup("body") {
            body = this.parseBody(decl.getGroupValue("body").rule())
        }

        return new AstFunction {
            scope = this.scope
            modifiers
            name
            generics
            params
            returnType
            varargs
            body
        }
    }

    parseGetAccessorDecl(ast: RuleMatch): AstAccessor {
        let modifiers = this.parseModifers(ast)
        let name = tokenizeIdentifier(ast.getGroupValue("name").token())
        let type = this.parseValueType(ast.getGroupValue("type").rule())
        let body: ?List<AstToken<AstStatement>> = null
        if ast.hasGroup("body") {
            body = this.parseBody(ast.getGroupValue("body").rule())
        }

        return new AstAccessor {
            kind = AccessorKind.Get
            modifiers
            name
            type
            body
        }
    }

    parseAnonymousTypeDecl(ast: RuleMatch): List<AstFieldDecl> {
        let astFields = ast.getGroup("fields")
        let fields = List.withCapacity<AstFieldDecl>(astFields.length)
        for astField in astFields {
            let rule = astField.rule()
            let name = tokenizeIdentifier(rule.getGroupValue("name").token())
            let type = this.parseValueType(rule.getGroupValue("type").rule()) 
            fields.push(new AstFieldDecl {
                name
                type
            })
        }
        return fields
    }

    parseClass(ast: RuleMatch): AstClass {
        let modifiers = this.parseModifers(ast)
        let classKindAst = ast.getGroupValue("kind").token()
        let kind = tokenize<ObjectKind>(classKindAst.loc, match classKindAst.kind.keyword() {
            "class" => ObjectKind.Class
            "struct" => ObjectKind.Struct
            "interface" => ObjectKind.Interface
            "enum" => ObjectKind.Enum
        })

        let name = tokenizeIdentifier(ast.getGroupValue("name").token())
        let generics: ?List<AstGenericDecl> = null
        if ast.hasGroup("generics") {
            generics = this.parseGenericDecls(ast.getGroupValue("generics").rule())
        }

        let superclass: ?AstToken<string> = null
        let superclassGenerics: ?List<AstToken<ComplexType>> = null
        if ast.hasGroup("extends") {
            let extendsDecl = ast.getGroupValue("extends").rule()
            let superclassDecl = extendsDecl.getGroupValue("superclass").rule()
            superclass = parseQualifiedPath(superclassDecl)
            superclassGenerics = this.parseGenericArgs(extendsDecl, "generics")
        }

        let enumMembers = List.empty<AstEnumMember>()
        if ast.hasGroup("members") {
            for member in ast.getGroup("members") {
                let rule = member.rule()
                let memberName = tokenizeIdentifier(rule.getGroupValue("name").token())
                let memberData = List.empty<AstFieldDecl>()
                if rule.hasGroup("data") {
                    memberData = this.parseAnonymousTypeDecl(rule.getGroupValue("data").rule())
                }
                enumMembers.push(new AstEnumMember {
                    name = memberName
                    data = memberData
                })
            }
        }

        let destructor: ?List<AstToken<AstStatement>> = null
        let associatedTypes = List.empty<AstAssociatedType>()
        let fields = List.empty<AstClassField>()
        let methods = List.empty<AstFunction>()
        let accessors = List.empty<AstAccessor>()
        if ast.hasGroup("statements") {
            let statements = ast.getGroup("statements")
            for statement in statements {
                this.scope = DeclarationScope.Object
                let rule = statement.rule()
                match rule.ruleName {
                    "AssociatedTypeDecl" => {
                        associatedTypes.push(this.parseAssociatedTypeDecl(rule))
                    }
                    "DestructorDecl"  => destructor  = this.parseBody(rule.getGroupValue("body").rule())
                    "FieldDecl" => {
                        fields.push(this.parseClassField(rule))
                    }
                    "MethodDecl" => {
                        methods.push(this.parseFunction(rule))
                    }
                    "GetAccessorDecl" => {
                        accessors.push(this.parseGetAccessorDecl(rule))
                    }
                    _ => {
                        io.println("TODO: Class-level statement: ", rule.ruleName)
                    }
                }
            }
        }

        return new AstClass {
            kind
            modifiers
            name
            generics
            superclass
            superclassGenerics
            destructor
            associatedTypes
            enumMembers
            fields
            methods
            accessors
        }
    }

    parseAssociatedTypeDecl(ast: RuleMatch): AstAssociatedType {
        let name = tokenizeIdentifier(ast.getGroupValue("name").token())
        let aliasee: ?AstToken<ComplexType> = null
        if ast.hasGroup("aliasee") {
            aliasee = this.parseValueType(ast.getGroupValue("aliasee").rule())
        }
        return new AstAssociatedType {
            name
            aliasee
        }
    }

    parseImplement(ast: RuleMatch): AstImplement {
        let generics: ?List<AstGenericDecl> = null
        if ast.hasGroup("generics") {
            generics = this.parseGenericDecls(ast.getGroupValue("generics").rule())
        }

        let interface = parseQualifiedPath(ast.getGroupValue("interface").rule())
        let interfaceGenerics: ?List<AstToken<ComplexType>> = this.parseGenericArgs(ast, "interfaceGenerics")
        let target = parseQualifiedPath(ast.getGroupValue("target").rule())
        let targetGenerics: ?List<AstToken<ComplexType>> = this.parseGenericArgs(ast, "targetGenerics")

        let associatedTypes = List.empty<AstAssociatedType>()
        let methods = List.empty<AstFunction>()

        for statement in ast.getGroup("statements") {
            this.scope = DeclarationScope.Object

            let rule = statement.rule()
            match rule.ruleName {
                "AssociatedTypeDecl" => {
                    associatedTypes.push(this.parseAssociatedTypeDecl(rule))
                }
                _ => {}
            }
        }

        return new AstImplement {
            generics
            interface
            interfaceGenerics
            target
            targetGenerics
            associatedTypes
            methods
        }
    }

    parseProgram(ast: RuleMatch): AstKeidProgram {
        let namespaceAst = ast.getGroupValue("namespace").rule().getGroupValue("namespace").rule()
        let namespace = parseQualifiedPath(namespaceAst)
        let imports = List.empty<AstToken<string>>()
        let classes = List.empty<AstClass>()
        let impls = List.empty<AstImplement>()
        let functions = List.empty<AstFunction>()
        let globals = List.empty<AstLet>()

        if ast.hasGroup("statements") {
            for statement in ast.getGroup("statements") {
                this.scope = DeclarationScope.Namespace

                let rule = statement.rule()
                match rule.ruleName {
                    "ImportStatement" => {
                        let namespaces = rule.getGroup("namespaces")
                        for namespace in namespaces {
                            imports.push(parseQualifiedPath(namespace.rule()))
                        }
                    }
                    "ClassDecl" => {
                        classes.push(this.parseClass(rule))
                    }
                    "EnumDecl" => {
                        classes.push(this.parseClass(rule))
                    }
                    "ImplementDecl" => {
                        impls.push(this.parseImplement(rule))
                    }
                    "FunctionDecl" => {
                        functions.push(this.parseFunction(rule))
                    }
                    "LetStatement" => {
                        globals.push(this.parseLet(rule.getGroupValue("let").rule()))
                    }
                    _ => throw Error.create("NotYetImplemented: root statement: " + rule.ruleName)
                }
            }
        }

        return new AstKeidProgram {
            file = this.file
            namespace
            imports
            classes
            impls
            functions
            globals
        }
    }
}

class KeidPreprocessor {
    ast: RuleMatch
    macroDecls: List<RuleMatch>
    macroCalls: List<RuleMatch>

    public static create(ast: RuleMatch, macroDecls: List<RuleMatch>): KeidPreprocessor => new KeidPreprocessor {
        ast
        macroDecls
        macroCalls = List.empty<RuleMatch>()
    }

    public findMacroCalls(): bool {
        for statement in this.ast.getGroup("statements") {
            match statement {
                Rule { rule, } => {
                    if rule.ruleName == "MacroCall" {
                        this.macroCalls.push(rule)
                    }
                }
                _ => {}
            }
        }
        return this.macroCalls.length > 0
    }

    public preprocess(): List<LexerToken> {
        let tokens = this.collectRegularTokens()
        for macroCall in this.macroCalls {
            let macroName = macroCall.getGroupValue("name").token().kind.identifier()
            let macroParamValues = macroCall.getGroup("params")
            let macroDecl = this.findMacroDecl(macroName)
            let macroParamDecls = macroDecl.getGroup("params")
            let paramNames = List.withCapacity<string>(macroParamDecls.length)
            for macroParamDecl in macroParamDecls {
                paramNames.push(macroParamDecl.rule().getGroupValue("name").token().kind.identifier())
            }
            let macroBody = macroDecl.getGroup("body")
            let bodyTokens = List.withCapacity<LexerToken>(macroBody.length)
            for bodyToken in macroBody {
                bodyTokens.push(bodyToken.token())
            }
            let processedBody = this.preprocessMacroCall(paramNames, macroParamValues, bodyTokens)
            tokens.extend(processedBody)
        }
        return tokens
    }

    /// Returns all tokens outside of macro calls and definitions.
    collectRegularTokens(): List<LexerToken> {
        let tokens = List.empty<LexerToken>()
        for statement in this.ast.getGroup("statements") {
            match statement {
                Token { token, } => {
                    tokens.push(token)
                }
                _ => {}
            }
        }
        return tokens
    }

    findMacroDecl(name: string): RuleMatch {
        for macroDecl in this.macroDecls {
            let macroName = macroDecl.getGroupValue("name").token().kind.identifier()
            if macroName == name {
                return macroDecl
            }
        }
        throw Error.create(string.format("no such MacroDecl '", name, "'"))
    }
    
    replaceIdentifierName(paramName: string, paramValue: ParserMatch, identifierName: string, loc: TokenLocation): LexerToken {
        match paramValue {
            Token { token, } => {
                match token.kind {
                    Identifier { name, } => {
                        return new LexerToken {
                            kind = new LexerTokenKind.Identifier {
                                name = identifierName.replaceFirst(paramName, name)
                            }
                            loc
                            originalLoc = token.loc
                        }
                        
                    }
                    _ => {}
                }
            }
            _ => {}
        }
        throw Error.create(string.format("param '", paramName, "' should be an identifier"))
    }

    preprocessToken(paramNames: List<string>, paramValues: List<ParserMatch>, bodyToken: LexerToken, name: string): List<LexerToken> {
        for p in range.create(paramNames.length) {
            let paramName = paramNames.elementAt(p)
            let paramValue = paramValues.elementAt(p)
            if paramName == name {
                match paramValue {
                    Rule { rule, } => {
                        return rule.getAllTokens()
                    }
                    Token { token, } => {
                        token.originalLoc = bodyToken.loc
                        return List.from<LexerToken>(token)
                    }
                }
            }
            if name.contains(paramName) {
                return List.from<LexerToken>(this.replaceIdentifierName(paramName, paramValue, name, bodyToken.loc))
            }
        }
        return List.from<LexerToken>(bodyToken)
    }

    preprocessMacroCall(paramNames: List<string>, paramValues: List<ParserMatch>, body: List<LexerToken>): List<LexerToken> {
        let processedTokens = List.withCapacity<LexerToken>(body.length)
        for bodyToken in body {
            match bodyToken.kind {
                Identifier { name, } => {
                    processedTokens.extend(this.preprocessToken(paramNames, paramValues, bodyToken, name))
                    continue
                }
                _ => {}
            }
            processedTokens.push(bodyToken)
        }
        return processedTokens
    }
}

public function createPreprocessor(): KsdlParser {
    let syntaxDefFile = File.open("../keid/assets/compiler/preprocessor.ksdl", FileOpenMode.ReadOnly)
    let syntaxDef = string.fromUtf8(syntaxDefFile.readAllBytes())
    syntaxDefFile.close()

    return KsdlParser.fromKsdl(syntaxDef)
}

public function createParser(): KsdlParser {
    let syntaxDefFile = File.open("../keid/assets/compiler/syntax.ksdl", FileOpenMode.ReadOnly)
    let syntaxDef = string.fromUtf8(syntaxDefFile.readAllBytes())
    syntaxDefFile.close()

    return KsdlParser.fromKsdl(syntaxDef)
}

function findMacroDecls(ast: RuleMatch): List<RuleMatch> {
    let decls = List.empty<RuleMatch>()
    for statement in ast.getGroup("statements") {
        match statement {
            Rule { rule, } => {
                if rule.ruleName == "MacroDecl" {
                    decls.push(rule)
                }
            }
            _ => {}
        }
    }
    return decls
}

function runPreprocessorParser(preprocessor: KsdlParser, reader: TokenReader, stream: TokenStream, file: string, programText: string): RuleMatch {
    let preprocesserRule = preprocessor.getRule("PreprocessorProgram")
    let preprocessResult = preprocesserRule.parse(stream)
    if !stream.isFinished {
        reader.cursor = stream.currentToken.loc.start
        let pos = reader.documentPosition
        io.println("failed preprocessing rule '",
            stream.currentRule!.name,
            "' at ",
            stream.currentToken.name,
            " '",
            stream.currentToken.loc.getText(programText),
            "' @ ",
            file,
            ":",
            pos.line.toString(),
            ":",
            pos.col.toString(),
        )
        for i in range.create(10) {
            if stream.isFinished {
                break
            }
            stream.next()
            io.println("next token: ", stream.currentToken.name, " '", stream.currentToken.loc.getText(programText), "'")
        }
        throw Error.create("failed preprocessing rule")
    }

    match preprocessResult {
        Success { match, } => {
            return match.rule()
        }
        HardFail { statement, result, } => {
            throw Error.create(string.format("Failed preprocessing statement: ", statement.describe()))
        }
        _ => {}
    }

    unreachable
}

function preprocess(preprocessor: KsdlParser, reader: TokenReader, stream: TokenStream, file: string, programText: string, macroDecls: List<RuleMatch>): List<LexerToken> {
    let result = runPreprocessorParser(preprocessor, reader, stream, file, programText)
    let kp = KeidPreprocessor.create(result, macroDecls)
    if kp.findMacroCalls() {
        let processedTokens = kp.preprocess()
        let processedStream = TokenStream.create(processedTokens)
        return preprocess(preprocessor, reader, processedStream, file, programText, macroDecls)
    }
    return stream.tokens
}

public function parseKeidSource(preprocessor: KsdlParser, parser: KsdlParser, file: string): AstKeidProgram {
    let programFile = File.open(file, FileOpenMode.ReadOnly)
    let programText = String.fromUtf8(programFile.readAllBytes())
    programFile.close()

    let reader = TokenReader.create(programText)
    let tokens = ksdl.tokenize(reader, file)
    let stream = TokenStream.create(tokens)

    let initialPreprocessResult = runPreprocessorParser(preprocessor, reader, stream, file, programText)
    let macroDecls = findMacroDecls(initialPreprocessResult)

    stream.offset = 0
    let processedTokens = preprocess(preprocessor, reader, stream, file, programText, macroDecls)
    let processedStream = TokenStream.create(processedTokens)

    let programRule = parser.getRule("Program")
    let parseResult = programRule.parse(processedStream)
    if !stream.isFinished {
        reader.cursor = stream.currentToken.loc.start
        let pos2 = reader.documentPosition
        io.println("failed parsing rule '",
            stream.currentRule!.name,
            "' at ",
            stream.currentToken.name,
            " '",
            stream.currentToken.loc.getText(programText),
            "' @ ",
            file,
            ":",
            pos2.line.toString(),
            ":",
            pos2.col.toString(),
        )
        for i in range.create(10) {
            if stream.isFinished {
                break
            }
            stream.next()
            io.println("next token: ", stream.currentToken.name, " '", stream.currentToken.loc.getText(programText), "'")
        }
        throw Error.create("failed parsing rule")
    }
    match parseResult {
        Success { match, } => {
            let keidParser = new KeidParser {
                scope = DeclarationScope.Namespace
                file = new SourceFile {
                    path = file
                    text = programText
                }
            }
            return keidParser.parseProgram(match.rule())
        }
        HardFail { statement, result, loc, } => {
            io.println("Failed parsing statement: ", Class.fromInstance(statement).name)

            reader.cursor = loc.start
            let pos3 = reader.documentPosition
            io.println("expecting ",
                statement.describe(),
                " at ",
                file,
                ":",
                pos3.line.toString(),
                ":",
                pos3.col.toString(),
            )
        }
        _ => {}
    }

    throw Error.create("Parse failure!")
}
