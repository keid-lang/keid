namespace keidc::ksdl

import (
    core::collections
    core::error
    core::string
)

public enum LexerLiteral {
    Bool {
        val: bool
    }
    SignedInteger {
        val: int64
    }
    UnsignedInteger {
        val: uint64
    }
    String {
        val: String
    }
    Char {
        val: char
    }
    Null
}

public enum LexerTokenKind {
    Identifier {
        name: String
    }
    Keyword {
        name: String
    }
    Operator {
        op: String
    }
    Literal {
        lit: LexerLiteral
    }
    Newline
}

public struct LexerToken {
    loc: TokenLocation
    kind: LexerTokenKind
}

enum StringTokenizerState {
    Normal
    Escape
}

const KEYWORDS: [string] = new string[
    "as", "class", "const", "deref", "else", "end macro", "enum", "extends", "for",
    "get", "if", "implement", "import", "interface", "let", "macro", "match",
    "namespace", "ref", "return", "set", "struct", "throw", "type", "unsafe",
]
const OPERATORS: [string] = new string[
    "==", "!=", "+", "-", "*", "/", "%", "<<", ">>", "||", "&&", "<=", ">=", "=>", "<", ">",
    "!", "...", "as", "??", "?", "&", "|", "^", "=", "+=", "-=", "*=", "/=", "%=", ",",
    "<<=", ">>=", "&=", "|=", "^=", "::", ":", ".", "(", ")", "[", "]", "{", "}",
]

public function tokenize(reader: TokenReader): List<LexerToken> {
    let tokens = List.empty<LexerToken>()
    let currentToken = StringBuilder.empty()

    reader.isSkipWhitespace = true
    while !reader.isFinished {
        if reader.currentCharacter == '\n' || reader.startsWith("\r\n") {
            tokens.push(new LexerToken {
                loc = TokenLocation.create(reader.cursor, 1)
                kind = LexerTokenKind.Newline
            })
            let adv: usize = match reader.currentCharacter {
                '\n' => 1
                _ => 2
            }
            reader.advance(adv)
        } else if reader.currentCharacter == '"' || reader.currentCharacter == '\'' {
            let start = reader.cursor
            let delimiter = reader.currentCharacter
            reader.advance(1)
            reader.isSkipWhitespace = false
            let str = tokenizeString(reader, delimiter)
            reader.isSkipWhitespace = true
            if delimiter == '\'' && str.length != 1 {
                throw Error.create("character literal must be exactly one character")
            }
            let lit = match delimiter {
                '"' => new LexerLiteral.String {
                    val = str
                }
                '\'' => new LexerLiteral.Char {
                    val = str.chars[0]
                }
            }
            tokens.push(new LexerToken {
                loc = TokenLocation.create(start, reader.cursor - start)
                kind = new LexerTokenKind.Literal {
                    lit
                }
            })
        } else if reader.currentCharacter.isNumber || reader.currentCharacter == '+' || reader.currentCharacter == '-' {
            let firstCharacter = reader.currentCharacter
            reader.advance(1)
            if firstCharacter == '+' || firstCharacter == '-' {
                if !reader.currentCharacter.isNumber {

                }
            }
            reader.isSkipWhitespace = false
            reader.isSkipWhitespace = true
        } else {
            let cursor = reader.cursor
            if advanceKeyword(reader, "null") {
                tokens.push(new LexerToken {
                    loc = TokenLocation.create(cursor, 4)
                    kind = new LexerTokenKind.Literal {
                        lit = LexerLiteral.Null
                    }
                })
            }
            if advanceKeyword(reader, "true") {
                tokens.push(new LexerToken {
                    loc = TokenLocation.create(cursor, 4)
                    kind = new LexerTokenKind.Literal {
                        lit = new LexerLiteral.Bool {
                            val = true
                        }
                    }
                })
            }
            if advanceKeyword(reader, "false") {
                tokens.push(new LexerToken {
                    loc = TokenLocation.create(cursor, 5)
                    kind = new LexerTokenKind.Literal {
                        lit = new LexerLiteral.Bool {
                            val = false
                        }
                    }
                })
            }
            if tokenizeOperator(reader, tokens) {
                continue
            }
            if tokenizeKeyword(reader, tokens) {
                continue
            }
            if tokenizeIdentifier(reader, tokens) {
                continue
            }

            throw Error.create(string.format("unexpected token '", reader.currentCharacter.toString(), "'"))
        }
    }

    return tokens
}

function advanceKeyword(reader: TokenReader, keyword: string): bool {
    if reader.startsWith(keyword) {
        reader.advance(keyword.length)
        if !isCharIdentifierComponent(reader.currentCharacter) {
            return true
        } else {
            reader.retreat(keyword.length)
        }
    }
    return false
}

function tokenizeKeyword(reader: TokenReader, tokens: List<LexerToken>): bool {
    for keyword in KEYWORDS {
        let cursor = reader.cursor
        if advanceKeyword(reader, keyword) {
            tokens.push(new LexerToken {
                loc = TokenLocation.create(cursor, keyword.length)
                kind = new LexerTokenKind.Keyword {
                    name = keyword
                }
            })
            return true
        }
    }
    return false
}

function tokenizeIdentifier(reader: TokenReader, tokens: List<LexerToken>): bool {
    if isCharIdentifierComponent(reader.currentCharacter) {
        let cursor = reader.cursor
        let sb = StringBuilder.withCapacity(1)
        while !reader.isFinished && isCharIdentifierComponent(reader.currentCharacter) {
            sb.append(reader.currentCharacter)
            reader.advance(1)
        }
        let ident = sb.toString()
        tokens.push(new LexerToken {
            loc = TokenLocation.create(cursor, ident.length)
            kind = new LexerTokenKind.Identifier {
                name = ident
            }
        })
        return true
    }
    return false
}

function tokenizeOperator(reader: TokenReader, tokens: List<LexerToken>): bool {
    for operator in OPERATORS {
        if reader.startsWith(operator) {
            tokens.push(new LexerToken {
                loc = TokenLocation.create(reader.cursor, operator.length)
                kind = new LexerTokenKind.Operator {
                    op = operator
                }
            })
            reader.advance(operator.length)
            return true
        }
    }
    return false
}

function tokenizeString(reader: TokenReader, delimiter: char): string {
    let state = StringTokenizerState.Normal
    let builder = StringBuilder.empty()
    while !reader.isFinished {
        let c = reader.currentCharacter
        reader.advance(1)

        match state {
            Normal => {
                match c {
                    '"' => return builder.toString()
                    '\'' => return builder.toString()
                    '\\' => {
                        state = StringTokenizerState.Escape
                    }
                    _ => {
                        builder.append(c)
                    }
                }
            }
            Escape => {
                let m = match c {
                    '"' => '"'
                    '\'' => '\''
                    '\\' => '\\'
                    '0' => '\0'
                    'n' => '\n'
                    'r' => '\r'
                    't' => '\t'
                    _ => throw Error.create("Invalid escape sequence")
                }
                builder.append(m)
                state = StringTokenizerState.Normal
            }
        }
    }
    throw Error.create("unexpected EOF while tokenizing string")
}

function isCharIdentifierComponent(c: char): bool {
    return (c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z') || (c >= '0' && c <= '9') || c == '_'
}
